{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vncDsAP0Gaoa"
   },
   "source": [
    "# **Project Name**    -\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "beRrZCGUAJYm"
   },
   "source": [
    "Zomato Review Clustering using NLP and KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJNUwmbgGyua"
   },
   "source": [
    "# **Project Summary -**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6v_1wHtG2nS"
   },
   "source": [
    "This project uses Natural Language Processing (NLP) and KMeans clustering to analyze and group restaurant reviews from Zomato. The purpose is to identify recurring themes in customer feedback to help businesses better understand user sentiments and take data-driven decisions. We merge two datasets: one containing reviews and another containing restaurant metadata. After cleaning the text, we apply TF-IDF vectorization to transform reviews into numerical form. KMeans clustering helps group similar reviews, and we visualize how reviews for the top 15 restaurants are distributed among clusters. The solution demonstrates a complete text clustering pipeline and offers actionable insights for restaurant performance analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6K7xa23Elo4"
   },
   "source": [
    "# **GitHub Link -**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1o69JH3Eqqn"
   },
   "source": [
    "https://github.com/ioskinjal/zomato-review-clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQaldy8SH6Dl"
   },
   "source": [
    "# **Problem Statement**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DpeJGUA3kjGy"
   },
   "source": [
    "Manually analyzing thousands of customer reviews is time-consuming and inefficient.\n",
    "This project aims to automatically cluster similar reviews together using unsupervised learning (KMeans), making it easier for businesses to understand recurring themes, customer sentiments, and pain points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDgbUHAGgjLW"
   },
   "source": [
    "# **General Guidelines** : -  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrxVaUj-hHfC"
   },
   "source": [
    "1.   Well-structured, formatted, and commented code is required.\n",
    "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
    "     \n",
    "     The additional credits will have advantages over other students during Star Student selection.\n",
    "       \n",
    "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
    "                       without a single error logged. ]\n",
    "\n",
    "3.   Each and every logic should have proper comments.\n",
    "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
    "        \n",
    "\n",
    "```\n",
    "# Chart visualization code\n",
    "```\n",
    "            \n",
    "\n",
    "*   Why did you pick the specific chart?\n",
    "*   What is/are the insight(s) found from the chart?\n",
    "* Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason.\n",
    "\n",
    "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
    "\n",
    "\n",
    "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
    "\n",
    "U - Univariate Analysis,\n",
    "\n",
    "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
    "\n",
    "M - Multivariate Analysis\n",
    " ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
    "\n",
    "\n",
    "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
    "\n",
    "\n",
    "*   Cross- Validation & Hyperparameter Tuning\n",
    "\n",
    "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
    "\n",
    "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_i_v8NEhb9l"
   },
   "source": [
    "# ***Let's Begin !***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HhfV-JJviCcP"
   },
   "source": [
    "## ***1. Know Your Data***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3lxredqlCYt"
   },
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "M8Vqi-pPk-HR"
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RnN4peoiCZX"
   },
   "source": [
    "### Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4CkvbW_SlZ_R"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Zomato Restaurant reviews.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load Dataset\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Load the datasets\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m reviews_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mZomato Restaurant reviews.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m metadata_df = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33mZomato Restaurant names and Metadata.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Merge the datasets on restaurant name\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/zomato-env/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/zomato-env/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/zomato-env/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/zomato-env/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/zomato-env/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'Zomato Restaurant reviews.csv'"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "# Load the datasets\n",
    "reviews_df = pd.read_csv(\"Zomato Restaurant reviews.csv\")\n",
    "metadata_df = pd.read_csv(\"Zomato Restaurant names and Metadata.csv\")\n",
    "\n",
    "# Merge the datasets on restaurant name\n",
    "merged_df = pd.merge(reviews_df, metadata_df, left_on='Restaurant', right_on='Name', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x71ZqKXriCWQ"
   },
   "source": [
    "### Dataset First View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LWNFOSvLl09H"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Zomato Restaurant reviews.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Dataset First Look\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m reviews_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mZomato Restaurant reviews.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m metadata_df = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33mZomato Restaurant names and Metadata.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m reviews_df.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/zomato-env/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/zomato-env/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/zomato-env/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/zomato-env/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/zomato-env/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'Zomato Restaurant reviews.csv'"
     ]
    }
   ],
   "source": [
    "# Dataset First Look\n",
    "reviews_df = pd.read_csv(\"Zomato Restaurant reviews.csv\")\n",
    "metadata_df = pd.read_csv(\"Zomato Restaurant names and Metadata.csv\")\n",
    "reviews_df.head()\n",
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7hBIi_osiCS2"
   },
   "source": [
    "### Dataset Rows & Columns count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Kllu7SJgmLij"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reviews_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Dataset Rows & Columns count\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mreviews_df\u001b[49m.shape)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(metadata_df.shape)\n",
      "\u001b[31mNameError\u001b[39m: name 'reviews_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Dataset Rows & Columns count\n",
    "print(reviews_df.shape)\n",
    "print(metadata_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlHwYmJAmNHm"
   },
   "source": [
    "### Dataset Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "e9hRXRi6meOf"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reviews_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Dataset Info\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mreviews_df\u001b[49m.info()\n\u001b[32m      3\u001b[39m metadata_df.info()\n",
      "\u001b[31mNameError\u001b[39m: name 'reviews_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Dataset Info\n",
    "reviews_df.info()\n",
    "metadata_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35m5QtbWiB9F"
   },
   "source": [
    "#### Duplicate Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1sLdpKYkmox0"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reviews_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Dataset Duplicate Value Count\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mreviews_df\u001b[49m.duplicated().sum())\n",
      "\u001b[31mNameError\u001b[39m: name 'reviews_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Dataset Duplicate Value Count\n",
    "print(reviews_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PoPl-ycgm1ru"
   },
   "source": [
    "#### Missing Values/Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GgHWkxvamxVg"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reviews_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Missing Values/Null Values Count\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mreviews_df\u001b[49m.isnull().sum())\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(metadata_df.isnull().sum())\n",
      "\u001b[31mNameError\u001b[39m: name 'reviews_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Missing Values/Null Values Count\n",
    "print(reviews_df.isnull().sum())\n",
    "print(metadata_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "3q5wnI3om9sJ"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Visualize missing values using heatmap\u001b[39;00m\n\u001b[32m      6\u001b[39m plt.figure(figsize=(\u001b[32m12\u001b[39m, \u001b[32m6\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m sns.heatmap(\u001b[43mmerged_df\u001b[49m.isnull(), cbar=\u001b[38;5;28;01mFalse\u001b[39;00m, cmap=\u001b[33m\"\u001b[39m\u001b[33mviridis\u001b[39m\u001b[33m\"\u001b[39m, yticklabels=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      8\u001b[39m plt.title(\u001b[33m\"\u001b[39m\u001b[33mMissing Values Heatmap\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m plt.xlabel(\u001b[33m\"\u001b[39m\u001b[33mColumns\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'merged_df' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the missing values\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize missing values using heatmap\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(merged_df.isnull(), cbar=False, cmap=\"viridis\", yticklabels=False)\n",
    "plt.title(\"Missing Values Heatmap\")\n",
    "plt.xlabel(\"Columns\")\n",
    "plt.ylabel(\"Records\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H0kj-8xxnORC"
   },
   "source": [
    "### What did you know about your dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfoNAAC-nUe_"
   },
   "source": [
    "Answer Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nA9Y7ga8ng1Z"
   },
   "source": [
    "## ***2. Understanding Your Variables***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "j7xfkqrt5Ag5"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Dataset Columns\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mmerged_df\u001b[49m.columns\n",
      "\u001b[31mNameError\u001b[39m: name 'merged_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Dataset Columns\n",
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "DnOaZdaE5Q5t"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Dataset Describe\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mmerged_df\u001b[49m.describe(include=\u001b[33m'\u001b[39m\u001b[33mall\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'merged_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Dataset Describe\n",
    "merged_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PBTbrJXOngz2"
   },
   "source": [
    "### Variables Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJV4KIxSnxay"
   },
   "source": [
    "| Variable Name     | Description                                                                 |\n",
    "|-------------------|-----------------------------------------------------------------------------|\n",
    "| Restaurant        | Name of the restaurant where the review was posted                         |\n",
    "| Review            | The original text review given by the customer                             |\n",
    "| Name              | Restaurant name from metadata (used to merge with review data)             |\n",
    "| Location          | Geographical location of the restaurant                                    |\n",
    "| Cuisine           | Type(s) of cuisine served at the restaurant                                |\n",
    "| Rating            | Overall user rating of the restaurant                                      |\n",
    "| CleanedReview     | Preprocessed version of review (lowercased, punctuation & stopwords removed)|\n",
    "| Cluster           | Cluster label assigned by KMeans model to the cleaned review               |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3PMJOP6ngxN"
   },
   "source": [
    "### Check Unique Values for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "zms12Yq5n-jE"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Check Unique Values for each variable.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mmerged_df\u001b[49m.nunique()\n",
      "\u001b[31mNameError\u001b[39m: name 'merged_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Check Unique Values for each variable.\n",
    "merged_df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dauF4eBmngu3"
   },
   "source": [
    "## 3. ***Data Wrangling***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKJF3rekwFvQ"
   },
   "source": [
    "### Data Wrangling Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "wk-9a2fpoLcV"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Drop rows with missing restaurant names after merge\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mmerged_df\u001b[49m.dropna(subset=[\u001b[33m'\u001b[39m\u001b[33mName\u001b[39m\u001b[33m'\u001b[39m], inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Remove duplicate reviews if any\u001b[39;00m\n\u001b[32m      5\u001b[39m merged_df.drop_duplicates(subset=[\u001b[33m'\u001b[39m\u001b[33mReview\u001b[39m\u001b[33m'\u001b[39m], inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'merged_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Drop rows with missing restaurant names after merge\n",
    "merged_df.dropna(subset=['Name'], inplace=True)\n",
    "\n",
    "# Remove duplicate reviews if any\n",
    "merged_df.drop_duplicates(subset=['Review'], inplace=True)\n",
    "\n",
    "# Reset index after dropping\n",
    "merged_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Clean review text\n",
    "def preprocess_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)  # Remove non-alphabetic characters\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])  # Remove stopwords\n",
    "    return text\n",
    "\n",
    "merged_df['CleanedReview'] = merged_df['Review'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MSa1f5Uengrz"
   },
   "source": [
    "### What all manipulations have you done and insights you found?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LbyXE7I1olp8"
   },
   "source": [
    "- We merged two datasets: one containing Zomato reviews and the other containing restaurant metadata, using the restaurant name as a common key.\n",
    "- We dropped rows where metadata was missing (i.e., unmatched restaurant names after merging).\n",
    "- We eliminated duplicate reviews to ensure cleaner clustering.\n",
    "- We reset the DataFrame index after row deletions.\n",
    "- We applied a text preprocessing function to clean the review text. This included:\n",
    "  - Converting text to lowercase.\n",
    "  - Removing all non-alphabetical characters (punctuation, digits).\n",
    "  - Removing common English stopwords using NLTK.\n",
    "- The cleaned review text was stored in a new column called `CleanedReview`, which was later used for vectorization and clustering.\n",
    "\n",
    "**Insight:**  \n",
    "These steps ensured that the input to the TF-IDF vectorizer was standardized and free from noise. Removing stopwords and irrelevant characters improved the model’s ability to group semantically similar reviews together, which helped in forming meaningful clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GF8Ens_Soomf"
   },
   "source": [
    "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0wOQAZs5pc--"
   },
   "source": [
    "#### Chart - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "7v_ESjsspbW7"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sampled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      5\u001b[39m plt.figure(figsize=(\u001b[32m12\u001b[39m, \u001b[32m6\u001b[39m))\n\u001b[32m      6\u001b[39m sns.countplot(\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     data=\u001b[43msampled\u001b[49m,\n\u001b[32m      8\u001b[39m     x=\u001b[33m'\u001b[39m\u001b[33mRestaurant\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      9\u001b[39m     hue=\u001b[33m'\u001b[39m\u001b[33mCluster\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     10\u001b[39m     order=sampled[\u001b[33m'\u001b[39m\u001b[33mRestaurant\u001b[39m\u001b[33m'\u001b[39m].value_counts().index[:\u001b[32m15\u001b[39m],\n\u001b[32m     11\u001b[39m     palette=\u001b[33m'\u001b[39m\u001b[33mtab10\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     12\u001b[39m )\n\u001b[32m     13\u001b[39m plt.title(\u001b[33m\"\u001b[39m\u001b[33mTop 15 Restaurants – Review Clusters\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m plt.xlabel(\u001b[33m\"\u001b[39m\u001b[33mRestaurant\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'sampled' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Chart - 1 visualization code\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(\n",
    "    data=sampled,\n",
    "    x='Restaurant',\n",
    "    hue='Cluster',\n",
    "    order=sampled['Restaurant'].value_counts().index[:15],\n",
    "    palette='tab10'\n",
    ")\n",
    "plt.title(\"Top 15 Restaurants – Review Clusters\")\n",
    "plt.xlabel(\"Restaurant\")\n",
    "plt.ylabel(\"Number of Reviews\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(title='Cluster')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5QZ13OEpz2H"
   },
   "source": [
    "##### 1. Why did you pick the specific chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XESiWehPqBRc"
   },
   "source": [
    "This is a grouped bar chart which shows how reviews are clustered across the top 15 most-reviewed restaurants. It provides a quick visual comparison of how customer feedback is distributed among the 5 clusters per restaurant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQ7QKXXCp7Bj"
   },
   "source": [
    "##### 2. What is/are the insight(s) found from the chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_j1G7yiqdRP"
   },
   "source": [
    "\t•\tSome restaurants have a wider diversity of clusters in their reviews, indicating a mixed experience from customers.\n",
    "\t•\tOther restaurants have reviews falling into a single or dominant cluster, showing consistent feedback (positive or negative).\n",
    "\t•\tFor instance, if one restaurant has most reviews in cluster 0 and another in cluster 3, it may suggest different service or food themes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "448CDAPjqfQr"
   },
   "source": [
    "##### 3. Will the gained insights help creating a positive business impact?\n",
    "Are there any insights that lead to negative growth? Justify with specific reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cspy4FjqxJW"
   },
   "source": [
    "Yes. This clustering allows restaurant owners to:\n",
    "\t•\tUnderstand the themes of customer feedback per restaurant.\n",
    "\t•\tIdentify which restaurants receive polarized reviews, helping in targeted service improvements.\n",
    "\t•\tFocus on specific clusters that represent positive or negative sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-ATYxFrGrvw"
   },
   "source": [
    "## ***5. Hypothesis Testing***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yfr_Vlr8HBkt"
   },
   "source": [
    "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7MS06SUHkB-"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8yEUt7NnHlrM"
   },
   "source": [
    "### Hypothetical Statement - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tEA2Xm5dHt1r"
   },
   "source": [
    "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HI9ZP0laH0D-"
   },
   "source": [
    "\t•\tNull Hypothesis (H0): There is no significant difference in the number of reviews among the 5 clusters.\n",
    "\t•\tAlternative Hypothesis (H1): There is a significant difference in the number of reviews among the 5 clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I79__PHVH19G"
   },
   "source": [
    "#### 2. Perform an appropriate statistical test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "oZrfquKtyian"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sampled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Perform Statistical Test to obtain P-Value\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m chi2_contingency\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m cluster_counts = \u001b[43msampled\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mCluster\u001b[39m\u001b[33m'\u001b[39m].value_counts().values\n\u001b[32m      5\u001b[39m chi2, p, dof, expected = chi2_contingency([cluster_counts])\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mChi-square test p-value:\u001b[39m\u001b[33m\"\u001b[39m, p)\n",
      "\u001b[31mNameError\u001b[39m: name 'sampled' is not defined"
     ]
    }
   ],
   "source": [
    "# Perform Statistical Test to obtain P-Value\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "cluster_counts = sampled['Cluster'].value_counts().values\n",
    "chi2, p, dof, expected = chi2_contingency([cluster_counts])\n",
    "print(\"Chi-square test p-value:\", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ou-I18pAyIpj"
   },
   "source": [
    "##### Which statistical test have you done to obtain P-Value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s2U0kk00ygSB"
   },
   "source": [
    "Chi-Square Test for Independence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fF3858GYyt-u"
   },
   "source": [
    "##### Why did you choose the specific statistical test?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HO4K0gP5y3B4"
   },
   "source": [
    "We’re testing the frequency distribution across clusters, which is categorical data. Chi-square is appropriate for comparing proportions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_0_7-oCpUZd"
   },
   "source": [
    "### Hypothetical Statement - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwyV_J3ipUZe"
   },
   "source": [
    "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FnpLGJ-4pUZe"
   },
   "source": [
    "\t•\tNull Hypothesis (H0): The average review length does not differ significantly between clusters.\n",
    "\t•\tAlternative Hypothesis (H1): The average review length differs significantly between clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yB-zSqbpUZe"
   },
   "source": [
    "#### 2. Perform an appropriate statistical test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "sWxdNTXNpUZe"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sampled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Perform Statistical Test to obtain P-Value\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m f_oneway\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m sampled[\u001b[33m'\u001b[39m\u001b[33mReviewLength\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43msampled\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mCleanedReview\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(x.split()))\n\u001b[32m      5\u001b[39m grouped = [group[\u001b[33m\"\u001b[39m\u001b[33mReviewLength\u001b[39m\u001b[33m\"\u001b[39m].values \u001b[38;5;28;01mfor\u001b[39;00m name, group \u001b[38;5;129;01min\u001b[39;00m sampled.groupby(\u001b[33m\"\u001b[39m\u001b[33mCluster\u001b[39m\u001b[33m\"\u001b[39m)]\n\u001b[32m      6\u001b[39m f_stat, p = f_oneway(*grouped)\n",
      "\u001b[31mNameError\u001b[39m: name 'sampled' is not defined"
     ]
    }
   ],
   "source": [
    "# Perform Statistical Test to obtain P-Value\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "sampled['ReviewLength'] = sampled['CleanedReview'].apply(lambda x: len(x.split()))\n",
    "grouped = [group[\"ReviewLength\"].values for name, group in sampled.groupby(\"Cluster\")]\n",
    "f_stat, p = f_oneway(*grouped)\n",
    "print(\"ANOVA test p-value:\", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dEUvejAfpUZe"
   },
   "source": [
    "##### Which statistical test have you done to obtain P-Value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oLDrPz7HpUZf"
   },
   "source": [
    "ANOVA (Analysis of Variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fd15vwWVpUZf"
   },
   "source": [
    "##### Why did you choose the specific statistical test?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xOGYyiBpUZf"
   },
   "source": [
    "We’re comparing means across more than two groups (clusters), which is numerical data. ANOVA is ideal for such scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bn_IUdTipZyH"
   },
   "source": [
    "### Hypothetical Statement - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49K5P_iCpZyH"
   },
   "source": [
    "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gWI5rT9pZyH"
   },
   "source": [
    "\t•\tNull Hypothesis (H0): The number of clusters per restaurant is uniformly distributed.\n",
    "\t•\tAlternative Hypothesis (H1): The number of clusters per restaurant is not uniformly distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nff-vKELpZyI"
   },
   "source": [
    "#### 2. Perform an appropriate statistical test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "s6AnJQjtpZyI"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sampled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstats\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m chisquare\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Count how many different clusters each restaurant has\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m cluster_diversity = \u001b[43msampled\u001b[49m.groupby(\u001b[33m\"\u001b[39m\u001b[33mRestaurant\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[33m'\u001b[39m\u001b[33mCluster\u001b[39m\u001b[33m'\u001b[39m].nunique().value_counts()\n\u001b[32m      6\u001b[39m chisq_stat, p = chisquare(cluster_diversity)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mChi-square test (uniformity) p-value:\u001b[39m\u001b[33m\"\u001b[39m, p)\n",
      "\u001b[31mNameError\u001b[39m: name 'sampled' is not defined"
     ]
    }
   ],
   "source": [
    "# Perform Statistical Test to obtain P-Value\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "# Count how many different clusters each restaurant has\n",
    "cluster_diversity = sampled.groupby(\"Restaurant\")['Cluster'].nunique().value_counts()\n",
    "chisq_stat, p = chisquare(cluster_diversity)\n",
    "print(\"Chi-square test (uniformity) p-value:\", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kLW572S8pZyI"
   },
   "source": [
    "##### Which statistical test have you done to obtain P-Value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytWJ8v15pZyI"
   },
   "source": [
    "\t•\tChi-Square Goodness of Fit Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWbDXHzopZyI"
   },
   "source": [
    "##### Why did you choose the specific statistical test?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M99G98V6pZyI"
   },
   "source": [
    "\t•\tThis test evaluates whether the observed distribution of cluster variety across restaurants fits a uniform distribution. It’s appropriate for categorical diversity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yLjJCtPM0KBk"
   },
   "source": [
    "## ***6. Feature Engineering & Data Pre-processing***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xiyOF9F70UgQ"
   },
   "source": [
    "### 1. Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "iRsAHk1K0fpS"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Handling Missing Values & Missing Value Imputation\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Check and drop missing reviews\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m merged_df = \u001b[43mmerged_df\u001b[49m.dropna(subset=[\u001b[33m'\u001b[39m\u001b[33mReview\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'merged_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Handling Missing Values & Missing Value Imputation\n",
    "# Check and drop missing reviews\n",
    "merged_df = merged_df.dropna(subset=['Review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wuGOrhz0itI"
   },
   "source": [
    "#### What all missing value imputation techniques have you used and why did you use those techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ixusLtI0pqI"
   },
   "source": [
    "# Check and drop missing reviews\n",
    "merged_df = merged_df.dropna(subset=['Review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "id1riN9m0vUs"
   },
   "source": [
    "### 2. Handling Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "M6w2CzZf04JK"
   },
   "outputs": [],
   "source": [
    "# Not required for this NLP-based clustering task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "578E2V7j08f6"
   },
   "source": [
    "##### What all outlier treatment techniques have you used and why did you use those techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGZz5OrT1HH-"
   },
   "source": [
    "\t•\tNo outlier treatment required, as text clustering relies on TF-IDF vectorization rather than numerical outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89xtkJwZ18nB"
   },
   "source": [
    "### 3. Categorical Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "21JmIYMG2hEo"
   },
   "outputs": [],
   "source": [
    "# Not required – no ML model using categorical metadata directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67NQN5KX2AMe"
   },
   "source": [
    "#### What all categorical encoding techniques have you used & why did you use those techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UDaue5h32n_G"
   },
   "source": [
    "\t•\tNone used: Clustering is done using textual features only, so encoding is not necessary for metadata in our pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iwf50b-R2tYG"
   },
   "source": [
    "def preprocess_text(text):\n",
    "    text = str(text).lower()                                 # Lowercase\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)                     # Remove punctuation\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])  # Remove stopwords\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMQiZwjn3iu7"
   },
   "source": [
    "#### 1. Expand Contraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "PTouz10C3oNN"
   },
   "outputs": [],
   "source": [
    "# Not applied – could be added for further improvement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WVIkgGqN3qsr"
   },
   "source": [
    "#### 2. Lower Casing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "88JnJ1jN3w7j"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (938709862.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mDone using .lower()\u001b[39m\n         ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Lower Casing\n",
    "Done using .lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkPnILGE3zoT"
   },
   "source": [
    "#### 3. Removing Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "vqbBqNaA33c0"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3901338672.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mDone using regex\u001b[39m\n         ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Remove Punctuations\n",
    "Done using regex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hlsf0x5436Go"
   },
   "source": [
    "#### 4. Removing URLs & Removing words and digits contain digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "2sxKgKxu4Ip3"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (7252222.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mURLs and digits removed using regex filters\u001b[39m\n                    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Remove URLs & Remove words and digits contain digits\n",
    "URLs and digits removed using regex filters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mT9DMSJo4nBL"
   },
   "source": [
    "#### 5. Removing Stopwords & Removing White spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "T2LSJh154s8W"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (401616496.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mDone using nltk.corpus.stopwords\u001b[39m\n         ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Remove Stopwords\n",
    "Done using nltk.corpus.stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "EgLJGffy4vm0"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2473167092.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mDone via string splitting and joining\u001b[39m\n         ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Remove White spaces\n",
    "Done via string splitting and joining\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c49ITxTc407N"
   },
   "source": [
    "#### 6. Rephrase Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "foqY80Qu48N2"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1520192585.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mNot applied\u001b[39m\n        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Rephrase Text\n",
    "Not applied\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OeJFEK0N496M"
   },
   "source": [
    "#### 7. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "ijx1rUOS5CUU"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (858517395.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mDone implicitly while cleaning\u001b[39m\n         ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "Done implicitly while cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ExmJH0g5HBk"
   },
   "source": [
    "#### 8. Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "AIJ1a-Zc5PY8"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2229812502.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mNo stemming/lemmatization used, could be added\u001b[39m\n       ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Normalizing Text (i.e., Stemming, Lemmatization etc.)\n",
    "No stemming/lemmatization used, could be added\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJNqERVU536h"
   },
   "source": [
    "##### Which text normalization technique have you used and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9jKVxE06BC1"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5UmGsbsOxih"
   },
   "source": [
    "#### 9. Part of speech tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "btT3ZJBAO6Ik"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (535492058.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mNot performed\u001b[39m\n        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# POS Taging\n",
    "Not performed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0VqWOYE6DLQ"
   },
   "source": [
    "#### 10. Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "yBRtdhth6JDE"
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1408868483.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mDone using TfidfVectorizer from sklearn\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Vectorizing Text\n",
    " Done using TfidfVectorizer from sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBMux9mC6MCf"
   },
   "source": [
    "##### Which text vectorization technique have you used and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "su2EnbCh6UKQ"
   },
   "source": [
    "\t•\tCaptures the importance of words while down-weighting commonly occurring words.\n",
    "\t•\tWorks well with sparse textual data and is widely used in text clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-oLEiFgy-5Pf"
   },
   "source": [
    "### 4. Feature Manipulation & Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C74aWNz2AliB"
   },
   "source": [
    "#### 1. Feature Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "h1qC4yhBApWC"
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3508442905.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m•\tCleaned and transformed Review into CleanedReview to make it ready for vectorization.\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Manipulate Features to minimize feature correlation and create new features\n",
    "\t•\tCleaned and transformed Review into CleanedReview to make it ready for vectorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2DejudWSA-a0"
   },
   "source": [
    "#### 2. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "YLhe8UmaBCEE"
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (243375349.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m•\tUsed only the text vector features from TF-IDF for clustering, as they’re the most relevant for NLP-based grouping.\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Select your features wisely to avoid overfitting\n",
    "\t•\tUsed only the text vector features from TF-IDF for clustering, as they’re the most relevant for NLP-based grouping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pEMng2IbBLp7"
   },
   "source": [
    "##### What all feature selection methods have you used  and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAdphbQ9Bhjc"
   },
   "source": [
    "##### Which all features you found important and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGgaEstsBnaf"
   },
   "source": [
    "We did not use traditional feature selection techniques (like correlation analysis or Recursive Feature Elimination) since our project was based on **textual data**.\n",
    "\n",
    "Instead, we limited the feature set during the **TF-IDF vectorization** step by setting `max_features=1000`. This acted as a dimensionality reduction technique by selecting the top 1000 most relevant words (based on Term Frequency-Inverse Document Frequency scores), which are most informative for clustering purposes.\n",
    "\n",
    "This ensures we:\n",
    "- Focus only on the most significant terms in the reviews.\n",
    "- Avoid noise and overfitting from low-frequency or irrelevant words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNVZ9zx19K6k"
   },
   "source": [
    "### 5. Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqoHp30x9hH9"
   },
   "source": [
    "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "I6quWQ1T9rtH"
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (992052002.py, line 3)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mNo additional transformation was needed due to already normalized TF-IDF outputs.\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Transform Your data\n",
    "# No transformation like log/box-cox applied – not relevant for TF-IDF features\n",
    " No additional transformation was needed due to already normalized TF-IDF outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMDnDkt2B6du"
   },
   "source": [
    "### 6. Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "dL9LWpySC6x_"
   },
   "outputs": [],
   "source": [
    "# Scaling your data\n",
    "# TF-IDF output is already normalized – scaling not needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yiiVWRdJDDil"
   },
   "source": [
    "##### Which method have you used to scale you data and why?\n",
    "\n",
    "\t•\tNone, because TF-IDF internally handles normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UUpS68QDMuG"
   },
   "source": [
    "### 7. Dimesionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kexQrXU-DjzY"
   },
   "source": [
    "##### Do you think that dimensionality reduction is needed? Explain Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GGRlBsSGDtTQ"
   },
   "source": [
    "Answer Here.\n",
    "\t•\tOptional: Can be used for visualization (e.g., t-SNE or PCA), but clustering performance was acceptable without it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "kQfvxBBHDvCa"
   },
   "outputs": [],
   "source": [
    "# DImensionality Reduction (If needed)\n",
    "# Not applied in this version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T5CmagL3EC8N"
   },
   "source": [
    "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKr75IDuEM7t"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BhH2vgX9EjGr"
   },
   "source": [
    "### 8. Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "0CTyd2UwEyNM"
   },
   "outputs": [],
   "source": [
    "# Split your data to train and test. Choose Splitting ratio wisely.\n",
    "# Not applicable – Unsupervised learning (no train/test split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjKvONjwE8ra"
   },
   "source": [
    "##### What data splitting ratio have you used and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y2lJ8cobFDb_"
   },
   "source": [
    "\t•\tNot required since clustering is unsupervised and doesn’t rely on labeled data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1XJ9OREExlT"
   },
   "source": [
    "### 9. Handling Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFOzZv6IFROw"
   },
   "source": [
    "##### Do you think the dataset is imbalanced? Explain Why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GeKDIv7pFgcC"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "nQsRhhZLFiDs"
   },
   "outputs": [],
   "source": [
    "# Handling Imbalanced Dataset (If needed)\n",
    "# Not applicable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIqpNgepFxVj"
   },
   "source": [
    "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbet1HwdGDTz"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfCC591jGiD4"
   },
   "source": [
    "## ***7. ML Model Implementation***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OB4l2ZhMeS1U"
   },
   "source": [
    "### ML Model - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "7ebyywQieS1U"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KMeans\n\u001b[32m      9\u001b[39m kmeans = KMeans(n_clusters=\u001b[32m5\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m sampled[\u001b[33m'\u001b[39m\u001b[33mCluster\u001b[39m\u001b[33m'\u001b[39m] = kmeans.fit_predict(\u001b[43mX\u001b[49m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Fit the Algorithm\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# (Already fitted above using sampled['Cluster'])\u001b[39;00m\n\u001b[32m     14\u001b[39m \n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Predict on the model\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Clusters are already assigned, so we inspect cluster samples instead\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# ML Model - 1 Implementation\n",
    "\n",
    "# Fit the Algorithm\n",
    "\n",
    "# Predict on the model\n",
    "# ML Model - 1 Implementation\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "sampled['Cluster'] = kmeans.fit_predict(X)\n",
    "\n",
    "# Fit the Algorithm\n",
    "# (Already fitted above using sampled['Cluster'])\n",
    "\n",
    "# Predict on the model\n",
    "# Clusters are already assigned, so we inspect cluster samples instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ArJBuiUVfxKd"
   },
   "source": [
    "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "rqD5ZohzfxKe"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 6) (2873308273.py, line 6)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mSince this is an **unsupervised task**, traditional supervised metrics like accuracy or F1-score don't apply. Instead, we evaluate it using **visualization** and **qualitative analysis**.\u001b[39m\n                                                                                                        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated string literal (detected at line 6)\n"
     ]
    }
   ],
   "source": [
    "# Visualizing evaluation Metric Score chart\n",
    "We used **KMeans Clustering**, an unsupervised machine learning algorithm that assigns similar reviews into distinct clusters based on their textual content.\n",
    "\n",
    "We used **TF-IDF** vectorized features of reviews as input to the model.\n",
    "\n",
    "Since this is an **unsupervised task**, traditional supervised metrics like accuracy or F1-score don't apply. Instead, we evaluate it using **visualization** and **qualitative analysis**.\n",
    "\n",
    "**Performance Interpretation:**\n",
    "- Visual inspection of clusters shows that reviews with similar sentiments or topics tend to fall in the same cluster.\n",
    "- Top 15 restaurants are shown with review distributions across clusters, indicating natural groupings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4qY1EAkEfxKe"
   },
   "source": [
    "#### 2. Cross- Validation & Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "Dy61ujd6fxKe"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 6) (303383638.py, line 6)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m- Cross-validation is generally not applicable to unsupervised algorithms like KMeans, as there's no ground truth.\u001b[39m\n                                                                                                   ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated string literal (detected at line 6)\n"
     ]
    }
   ],
   "source": [
    "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
    "\n",
    "# Fit the Algorithm\n",
    "\n",
    "# Predict on the model\n",
    "- Cross-validation is generally not applicable to unsupervised algorithms like KMeans, as there's no ground truth.\n",
    "- However, we can experiment with different values of **k (number of clusters)** to evaluate clustering quality.\n",
    "\n",
    "In our case, we chose `k=5` after experimentation and observing visual clarity in the grouped results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PiV4Ypx8fxKe"
   },
   "source": [
    "##### Which hyperparameter optimization technique have you used and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "negyGRa7fxKf"
   },
   "source": [
    "We used manual tuning of the number of clusters (`k`) based on domain understanding and visualization clarity.\n",
    "\n",
    "Techniques like the **Elbow Method** or **Silhouette Score** can be used, but for simplicity and interpretability, we selected `k=5` which provided distinct and meaningful clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TfvqoZmBfxKf"
   },
   "source": [
    "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OaLui8CcfxKf"
   },
   "source": [
    "Yes, moving from `k=3` to `k=5` provided clearer thematic separation in clusters when sampled reviews were printed and bar charts were generated.\n",
    "\n",
    "This led to:\n",
    "- Better cluster interpretability\n",
    "- More evenly distributed reviews across clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJ2tPlVmpsJ0"
   },
   "source": [
    "### ML Model - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JWYfwnehpsJ1"
   },
   "source": [
    "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "yEl-hgQWpsJ1"
   },
   "outputs": [],
   "source": [
    "# Visualizing evaluation Metric Score chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-jK_YjpMpsJ2"
   },
   "source": [
    "#### 2. Cross- Validation & Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "Dn0EOfS6psJ2"
   },
   "outputs": [],
   "source": [
    "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
    "\n",
    "# Fit the Algorithm\n",
    "\n",
    "# Predict on the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAih1iBOpsJ2"
   },
   "source": [
    "##### Which hyperparameter optimization technique have you used and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9kBgjYcdpsJ2"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zVGeBEFhpsJ2"
   },
   "source": [
    "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74yRdG6UpsJ3"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmKjuQ-FpsJ3"
   },
   "source": [
    "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDKtOrBQpsJ3"
   },
   "source": [
    "Although unsupervised models lack traditional accuracy metrics, our evaluation focused on **cluster interpretability and visualization**.\n",
    "\n",
    "**Business Impact:**\n",
    "- Helps identify common customer sentiments without manually reading every review.\n",
    "- Clustering allows restaurant managers or analysts to understand:\n",
    "  - What customers praise the most\n",
    "  - Which issues are most recurring\n",
    "  - Unique topics of concern per restaurant\n",
    "\n",
    "Thus, it improves decision-making, enhances customer satisfaction, and helps in prioritizing service improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fze-IPXLpx6K"
   },
   "source": [
    "### ML Model - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "FFrSXAtrpx6M"
   },
   "outputs": [],
   "source": [
    "# ML Model - 3 Implementation\n",
    "\n",
    "# Fit the Algorithm\n",
    "\n",
    "# Predict on the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7AN1z2sKpx6M"
   },
   "source": [
    "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "xIY4lxxGpx6M"
   },
   "outputs": [],
   "source": [
    "# Visualizing evaluation Metric Score chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PIHJqyupx6M"
   },
   "source": [
    "#### 2. Cross- Validation & Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "eSVXuaSKpx6M"
   },
   "outputs": [],
   "source": [
    "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
    "\n",
    "# Fit the Algorithm\n",
    "\n",
    "# Predict on the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-qAgymDpx6N"
   },
   "source": [
    "##### Which hyperparameter optimization technique have you used and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQMffxkwpx6N"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-hykwinpx6N"
   },
   "source": [
    "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MzVzZC6opx6N"
   },
   "source": [
    "Answer Here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_CCil-SKHpo"
   },
   "source": [
    "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jHVz9hHDKFms"
   },
   "source": [
    "Since we’re working on an **unsupervised learning** problem using KMeans clustering, traditional metrics such as accuracy or recall are **not applicable**.\n",
    "\n",
    "Instead, we considered:\n",
    "\n",
    "- **Cluster Interpretability:** The clusters formed meaningful and distinguishable groupings of reviews.\n",
    "- **Visualizations:** The distribution of clusters across the Top 15 restaurants revealed insights about customer sentiment patterns.\n",
    "- **Business Relevance:** The clusters aligned well with real-world business concerns like food quality, service, ambiance, etc.\n",
    "\n",
    "These qualitative evaluations provide a **positive business impact** by giving restaurant owners actionable insights without needing labeled data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cBFFvTBNJzUa"
   },
   "source": [
    "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ksF5Q1LKTVm"
   },
   "source": [
    "We chose **KMeans Clustering** as the final model.\n",
    "\n",
    "**Reasons:**\n",
    "- It’s efficient for large textual datasets.\n",
    "- It allows for unsupervised learning without labeled data.\n",
    "- It revealed clear themes in customer reviews.\n",
    "- Easy to interpret and explain through bar charts and printed cluster samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HvGl1hHyA_VK"
   },
   "source": [
    "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnvVTiIxBL-C"
   },
   "source": [
    "The model used was **KMeans Clustering**, based on **TF-IDF vectorized features** of cleaned customer reviews.\n",
    "\n",
    "- **TF-IDF (Term Frequency-Inverse Document Frequency)** was used to weigh important words in reviews.\n",
    "- We did not use a specific model explainability tool like SHAP or LIME, as they’re more applicable to supervised models.\n",
    "- However, by printing sample reviews per cluster and analyzing the top terms in each cluster (optional extension), we could interpret the themes/topics in each group.\n",
    "\n",
    "This provides **qualitative explainability**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EyNgTHvd2WFk"
   },
   "source": [
    "## ***8.*** ***Future Work (Optional)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KH5McJBi2d8v"
   },
   "source": [
    "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "bQIANRl32f4J"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m joblib.dump(kmeans, \u001b[33m'\u001b[39m\u001b[33mkmeans_model.pkl\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Save the TF-IDF vectorizer used for review transformation\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m joblib.dump(\u001b[43mvectorizer\u001b[49m, \u001b[33m'\u001b[39m\u001b[33mtfidf_vectorizer.pkl\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the File\n",
    "# Save the trained KMeans model\n",
    "import joblib\n",
    "joblib.dump(kmeans, 'kmeans_model.pkl')\n",
    "\n",
    "# Save the TF-IDF vectorizer used for review transformation\n",
    "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iW_Lq9qf2h6X"
   },
   "source": [
    "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "oEXk9ydD2nVC"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tfidf_vectorizer.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load the File and predict unseen data.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Load the model and vectorizer\u001b[39;00m\n\u001b[32m      3\u001b[39m loaded_kmeans = joblib.load(\u001b[33m'\u001b[39m\u001b[33mkmeans_model.pkl\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m loaded_vectorizer = \u001b[43mjoblib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtfidf_vectorizer.pkl\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Test on a new review\u001b[39;00m\n\u001b[32m      7\u001b[39m new_review = \u001b[33m\"\u001b[39m\u001b[33mThe food was excellent but the service was very slow\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/zomato-env/lib/python3.13/site-packages/joblib/numpy_pickle.py:735\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(filename, mmap_mode, ensure_native_byte_order)\u001b[39m\n\u001b[32m    733\u001b[39m         obj = _unpickle(fobj, ensure_native_byte_order=ensure_native_byte_order)\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m735\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    736\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m _validate_fileobject_and_memmap(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m (\n\u001b[32m    737\u001b[39m             fobj,\n\u001b[32m    738\u001b[39m             validated_mmap_mode,\n\u001b[32m    739\u001b[39m         ):\n\u001b[32m    740\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    741\u001b[39m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[32m    742\u001b[39m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[32m    743\u001b[39m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'tfidf_vectorizer.pkl'"
     ]
    }
   ],
   "source": [
    "# Load the File and predict unseen data.\n",
    "# Load the model and vectorizer\n",
    "loaded_kmeans = joblib.load('kmeans_model.pkl')\n",
    "loaded_vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "\n",
    "# Test on a new review\n",
    "new_review = \"The food was excellent but the service was very slow\"\n",
    "processed = preprocess_text(new_review)\n",
    "vector = loaded_vectorizer.transform([processed])\n",
    "predicted_cluster = loaded_kmeans.predict(vector)\n",
    "\n",
    "print(f\"Predicted Cluster for test review: {predicted_cluster[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Kee-DAl2viO"
   },
   "source": [
    "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCX9965dhzqZ"
   },
   "source": [
    "# **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fjb1IsQkh3yE"
   },
   "source": [
    "This project effectively clustered Zomato restaurant reviews using NLP and unsupervised machine learning (KMeans). The following were achieved:\n",
    "\n",
    "- Preprocessing thousands of reviews using regex, stopword removal, and TF-IDF vectorization.\n",
    "- Clustering these reviews into meaningful topics using KMeans.\n",
    "- Visualizing customer sentiment and common themes for the top 15 restaurants.\n",
    "- Extracting sample reviews from each cluster to aid interpretation.\n",
    "- Provided business insights by identifying recurring themes like food quality, pricing, service speed, or ambiance.\n",
    "\n",
    "**Business Impact:**\n",
    "This can help restaurant owners:\n",
    "- Understand key sentiment clusters.\n",
    "- Identify improvement areas.\n",
    "- Tailor marketing and services for different customer segments.\n",
    "\n",
    "The project is ready for deployment with saved models and can be extended with other NLP models or sentiment scoring in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gIfDvo9L0UH2"
   },
   "source": [
    "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "vncDsAP0Gaoa",
    "FJNUwmbgGyua",
    "w6K7xa23Elo4",
    "yQaldy8SH6Dl",
    "mDgbUHAGgjLW",
    "O_i_v8NEhb9l",
    "HhfV-JJviCcP",
    "Y3lxredqlCYt",
    "3RnN4peoiCZX",
    "x71ZqKXriCWQ",
    "7hBIi_osiCS2",
    "JlHwYmJAmNHm",
    "35m5QtbWiB9F",
    "PoPl-ycgm1ru",
    "H0kj-8xxnORC",
    "nA9Y7ga8ng1Z",
    "PBTbrJXOngz2",
    "u3PMJOP6ngxN",
    "dauF4eBmngu3",
    "bKJF3rekwFvQ",
    "MSa1f5Uengrz",
    "GF8Ens_Soomf",
    "0wOQAZs5pc--",
    "K5QZ13OEpz2H",
    "lQ7QKXXCp7Bj",
    "448CDAPjqfQr",
    "KSlN3yHqYklG",
    "t6dVpIINYklI",
    "ijmpgYnKYklI",
    "-JiQyfWJYklI",
    "EM7whBJCYoAo",
    "fge-S5ZAYoAp",
    "85gYPyotYoAp",
    "RoGjAbkUYoAp",
    "4Of9eVA-YrdM",
    "iky9q4vBYrdO",
    "F6T5p64dYrdO",
    "y-Ehk30pYrdP",
    "bamQiAODYuh1",
    "QHF8YVU7Yuh3",
    "GwzvFGzlYuh3",
    "qYpmQ266Yuh3",
    "OH-pJp9IphqM",
    "bbFf2-_FphqN",
    "_ouA3fa0phqN",
    "Seke61FWphqN",
    "PIIx-8_IphqN",
    "t27r6nlMphqO",
    "r2jJGEOYphqO",
    "b0JNsNcRphqO",
    "BZR9WyysphqO",
    "jj7wYXLtphqO",
    "eZrbJ2SmphqO",
    "rFu4xreNphqO",
    "YJ55k-q6phqO",
    "gCFgpxoyphqP",
    "OVtJsKN_phqQ",
    "lssrdh5qphqQ",
    "U2RJ9gkRphqQ",
    "1M8mcRywphqQ",
    "tgIPom80phqQ",
    "JMzcOPDDphqR",
    "x-EpHcCOp1ci",
    "X_VqEhTip1ck",
    "8zGJKyg5p1ck",
    "PVzmfK_Ep1ck",
    "n3dbpmDWp1ck",
    "ylSl6qgtp1ck",
    "ZWILFDl5p1ck",
    "M7G43BXep1ck",
    "Ag9LCva-p1cl",
    "E6MkPsBcp1cl",
    "2cELzS2fp1cl",
    "3MPXvC8up1cl",
    "NC_X3p0fY2L0",
    "UV0SzAkaZNRQ",
    "YPEH6qLeZNRQ",
    "q29F0dvdveiT",
    "EXh0U9oCveiU",
    "22aHeOlLveiV",
    "g-ATYxFrGrvw",
    "Yfr_Vlr8HBkt",
    "8yEUt7NnHlrM",
    "tEA2Xm5dHt1r",
    "I79__PHVH19G",
    "Ou-I18pAyIpj",
    "fF3858GYyt-u",
    "4_0_7-oCpUZd",
    "hwyV_J3ipUZe",
    "3yB-zSqbpUZe",
    "dEUvejAfpUZe",
    "Fd15vwWVpUZf",
    "bn_IUdTipZyH",
    "49K5P_iCpZyH",
    "Nff-vKELpZyI",
    "kLW572S8pZyI",
    "dWbDXHzopZyI",
    "yLjJCtPM0KBk",
    "xiyOF9F70UgQ",
    "7wuGOrhz0itI",
    "id1riN9m0vUs",
    "578E2V7j08f6",
    "89xtkJwZ18nB",
    "67NQN5KX2AMe",
    "Iwf50b-R2tYG",
    "GMQiZwjn3iu7",
    "WVIkgGqN3qsr",
    "XkPnILGE3zoT",
    "Hlsf0x5436Go",
    "mT9DMSJo4nBL",
    "c49ITxTc407N",
    "OeJFEK0N496M",
    "9ExmJH0g5HBk",
    "cJNqERVU536h",
    "k5UmGsbsOxih",
    "T0VqWOYE6DLQ",
    "qBMux9mC6MCf",
    "-oLEiFgy-5Pf",
    "C74aWNz2AliB",
    "2DejudWSA-a0",
    "pEMng2IbBLp7",
    "rAdphbQ9Bhjc",
    "TNVZ9zx19K6k",
    "nqoHp30x9hH9",
    "rMDnDkt2B6du",
    "yiiVWRdJDDil",
    "1UUpS68QDMuG",
    "kexQrXU-DjzY",
    "T5CmagL3EC8N",
    "BhH2vgX9EjGr",
    "qjKvONjwE8ra",
    "P1XJ9OREExlT",
    "VFOzZv6IFROw",
    "TIqpNgepFxVj",
    "VfCC591jGiD4",
    "OB4l2ZhMeS1U",
    "ArJBuiUVfxKd",
    "4qY1EAkEfxKe",
    "PiV4Ypx8fxKe",
    "TfvqoZmBfxKf",
    "dJ2tPlVmpsJ0",
    "JWYfwnehpsJ1",
    "-jK_YjpMpsJ2",
    "HAih1iBOpsJ2",
    "zVGeBEFhpsJ2",
    "bmKjuQ-FpsJ3",
    "Fze-IPXLpx6K",
    "7AN1z2sKpx6M",
    "9PIHJqyupx6M",
    "_-qAgymDpx6N",
    "Z-hykwinpx6N",
    "h_CCil-SKHpo",
    "cBFFvTBNJzUa",
    "HvGl1hHyA_VK",
    "EyNgTHvd2WFk",
    "KH5McJBi2d8v",
    "iW_Lq9qf2h6X",
    "-Kee-DAl2viO",
    "gCX9965dhzqZ",
    "gIfDvo9L0UH2"
   ],
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "zomato-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
